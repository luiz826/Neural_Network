{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classificação de Tumores utilizando Redes Neurais e a biblioteca TensorFlow 2.X.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KYEw7gzRZqJn",
        "xm1Vj9V_aJkl",
        "xej6D8hbatAH"
      ],
      "mount_file_id": "1l4-78gG89iYINnBJ4BKqSCEwM4bovDK_",
      "authorship_tag": "ABX9TyO3HdLAPWUDHctAEzW8DASS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luiz826/Neural_Network/blob/main/Classifica%C3%A7%C3%A3o_de_Tumores_utilizando_Redes_Neurais_e_a_biblioteca_TensorFlow_2_X.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX4uAnV3Z4e0"
      },
      "source": [
        "<h1><center>Classificação de Tumores utilizando Redes Neurais e a biblioteca TensorFlow 2.X</center></h1>\n",
        "\n",
        "<img src=\"https://images.unsplash.com/photo-1590859808308-3d2d9c515b1a?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1053&q=80\">\n",
        "\n",
        "<p1><center>photo by Uriel SC, on Unsplash</center></p1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYEw7gzRZqJn"
      },
      "source": [
        "### Importação de bibliotecas e carregamento dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unq6wOWQU9eH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da924efb-0021-4650-c715-8410d9e262b0"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh9Ezt3iVEN0"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Dados_formatados.csv\", sep=\";\", header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXWAKG3GwxO2",
        "outputId": "9b131bed-fd53-413f-ff69-3f85694ae16f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1095.0000</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8589.0</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3398.0</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4585.0</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1156.0000</td>\n",
              "      <td>3445.0</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.0000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5438.0</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>205.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0   1      2      3   ...      28        29        30         31\n",
              "0    842302   1  17.99  10.38  ...  0.7119    0.2654    0.4601    0.11890\n",
              "1    842517   1  20.57  17.77  ...  0.2416  186.0000  275.0000    0.08902\n",
              "2  84300903   1  19.69  21.25  ...  0.4504  243.0000    0.3613    0.08758\n",
              "3  84348301   1  11.42  20.38  ...  0.6869    0.2575    0.6638  173.00000\n",
              "4  84358402   1  20.29  14.34  ...  0.4000    0.1625    0.2364    0.07678\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC865WNEwzBV",
        "outputId": "10e1e24e-8ade-4808-dfc5-4d321d4193bd"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 32 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       569 non-null    int64  \n",
            " 1   1       569 non-null    int64  \n",
            " 2   2       569 non-null    float64\n",
            " 3   3       569 non-null    float64\n",
            " 4   4       569 non-null    float64\n",
            " 5   5       569 non-null    float64\n",
            " 6   6       569 non-null    float64\n",
            " 7   7       569 non-null    float64\n",
            " 8   8       569 non-null    float64\n",
            " 9   9       569 non-null    float64\n",
            " 10  10      569 non-null    float64\n",
            " 11  11      569 non-null    float64\n",
            " 12  12      569 non-null    float64\n",
            " 13  13      569 non-null    float64\n",
            " 14  14      569 non-null    float64\n",
            " 15  15      569 non-null    float64\n",
            " 16  16      569 non-null    float64\n",
            " 17  17      569 non-null    float64\n",
            " 18  18      569 non-null    float64\n",
            " 19  19      569 non-null    float64\n",
            " 20  20      569 non-null    float64\n",
            " 21  21      569 non-null    float64\n",
            " 22  22      569 non-null    float64\n",
            " 23  23      569 non-null    float64\n",
            " 24  24      569 non-null    float64\n",
            " 25  25      569 non-null    float64\n",
            " 26  26      569 non-null    float64\n",
            " 27  27      569 non-null    float64\n",
            " 28  28      569 non-null    float64\n",
            " 29  29      569 non-null    float64\n",
            " 30  30      569 non-null    float64\n",
            " 31  31      569 non-null    float64\n",
            "dtypes: float64(30), int64(2)\n",
            "memory usage: 142.4 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm1Vj9V_aJkl"
      },
      "source": [
        "### Pré-processamento dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kts6NzveXFH2"
      },
      "source": [
        "X = df.drop(columns=[0,1])\n",
        "y = df[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ghl-TPBXZhI",
        "outputId": "d8508194-eb60-4148-df8a-fe6663e18015"
      },
      "source": [
        "y.value_counts(normalize=True).plot(kind=\"pie\", labels=[\"Benignos\", \"Malignos\"])\n",
        "plt.ylabel(\"\")\n",
        "\n",
        "plt.xlabel(\"Tumores Benignos: \"+ str(round(y.value_counts(normalize=True).values[0]*100)) +\"%\" +\n",
        "           \"\\n\\nTumores Malignos: \"+ str(round(y.value_counts(normalize=True).values[1]*100)) +\"%\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPORf4LKXl_L",
        "outputId": "b1157fd5-a07b-4471-ca12-d52e446b763e"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T621aAX_X3lN"
      },
      "source": [
        "def normaliza(col: np.array):\n",
        "    '''\n",
        "    col -> nome da coluna \n",
        "\n",
        "    return -> coluna normalizada \n",
        "    '''\n",
        "    colMax = col.max()\n",
        "    colMin = col.min()\n",
        "\n",
        "    new_col = (col - colMin) / (colMax - colMin)\n",
        "\n",
        "    return new_col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3JAdoSWX6Cj"
      },
      "source": [
        "for i in X.columns:\n",
        "    X[i] = normaliza(X[i].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAyV5a-waUNi"
      },
      "source": [
        "X = X.values\n",
        "y = y.values.reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkx7A4AuawDc"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF_REnFVeYnq",
        "outputId": "592fb52f-9af9-49c2-b242-8a227ef52561"
      },
      "source": [
        "print(\"X_train shape: \", X_train.shape)\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"X_test shape: \", X_test.shape)\n",
        "print(\"y_test shape: \", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape:  (455, 30)\n",
            "y_train shape:  (455, 1)\n",
            "X_test shape:  (114, 30)\n",
            "y_test shape:  (114, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xej6D8hbatAH"
      },
      "source": [
        "### Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oatde0vXCyHx"
      },
      "source": [
        "obs: Após alguns testes, percebi que o modelo chegava a métricas diferentes com os mesmos hiperparametros. Por isso decidi guardar os resultados em listas e tirar uma média aritmética dos resultados após 10 execuções."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsCghwoMZVX4",
        "outputId": "06bc4463-4a64-4a46-aa49-e43232bb01a9"
      },
      "source": [
        "media_loss_test = []\n",
        "media_acc_test = []\n",
        "media_loss_train = []\n",
        "media_acc_train = []\n",
        "\n",
        "for i in range(10):\n",
        "    model = tf.keras.models.Sequential([\n",
        "                                        tf.keras.layers.Dense(units= 128, activation=\"relu\", input_shape=(X.shape[1], )), \n",
        "\n",
        "                                        tf.keras.layers.Dense(units= 64, activation=\"relu\"),\n",
        "                                                                                                                                              \n",
        "                                        tf.keras.layers.Dense(units= 2, activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    adam = tf.optimizers.Adam(learning_rate=0.005)\n",
        "    model.compile(optimizer=adam, loss=\"sparse_categorical_crossentropy\", metrics=\"sparse_categorical_accuracy\")\n",
        "\n",
        "    if i == 9:\n",
        "        print(\"Ultimo modelo sendo treinado:\\n\")\n",
        "        model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=1)    \n",
        "    else:\n",
        "        model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=0)\n",
        "\n",
        "    loss_test , acc_test = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    loss_train , acc_train = model.evaluate(X_train, y_train, verbose=0)\n",
        "\n",
        "    media_loss_test.append(loss_test)\n",
        "    media_acc_test.append(acc_test)\n",
        "\n",
        "    media_loss_train.append(loss_train)\n",
        "    media_acc_train.append(acc_train)\n",
        "    \n",
        "print(\"\\n\\nAs configurações do modelo usado: \\n\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ultimo modelo sendo treinado:\n",
            "\n",
            "Epoch 1/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5999 - sparse_categorical_accuracy: 0.7125\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.2453 - sparse_categorical_accuracy: 0.8782\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1770 - sparse_categorical_accuracy: 0.9352\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1480 - sparse_categorical_accuracy: 0.9220\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1466 - sparse_categorical_accuracy: 0.9320\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1084 - sparse_categorical_accuracy: 0.9691\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1091 - sparse_categorical_accuracy: 0.9695\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.0764 - sparse_categorical_accuracy: 0.9827\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1032 - sparse_categorical_accuracy: 0.9519\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1228 - sparse_categorical_accuracy: 0.9377\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.1376 - sparse_categorical_accuracy: 0.9316\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.0804 - sparse_categorical_accuracy: 0.9663\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0848 - sparse_categorical_accuracy: 0.9742\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9813\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.0538 - sparse_categorical_accuracy: 0.9742\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0386 - sparse_categorical_accuracy: 0.9865\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0315 - sparse_categorical_accuracy: 0.9876\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0460 - sparse_categorical_accuracy: 0.9821\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.0515 - sparse_categorical_accuracy: 0.9781\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.0623 - sparse_categorical_accuracy: 0.9833\n",
            "\n",
            "\n",
            "As configurações do modelo usado: \n",
            "\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_57 (Dense)             (None, 128)               3968      \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 12,354\n",
            "Trainable params: 12,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr4LXYqhClfi"
      },
      "source": [
        "###Resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYrm3nuWoJA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b97d9d-4ecf-4a43-feaa-683ac4b9b666"
      },
      "source": [
        "print(f\"\\nMédia da função de perda no conjunto de treino: {np.mean(media_loss_train):.2f}\\n\")\n",
        "print(f\"Média da acurácia no conjunto de treino: {np.mean(media_acc_train):.2f}\\n\")\n",
        "\n",
        "print(f\"\\nMédia da função de perda no conjunto de teste: {np.mean(media_loss_test):.2f}\\n\")\n",
        "print(f\"Média da acurácia no conjunto de teste: {np.mean(media_acc_test):.2f}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Média da função de perda no conjunto de treino: 0.05\n",
            "\n",
            "Média da acurácia no conjunto de treino: 0.98\n",
            "\n",
            "\n",
            "Média da função de perda no conjunto de teste: 0.15\n",
            "\n",
            "Média da acurácia no conjunto de teste: 0.95\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}